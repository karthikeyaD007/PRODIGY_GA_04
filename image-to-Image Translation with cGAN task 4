# Install necessary libraries (if not already installed)
!pip install torch torchvision

# Import libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.utils import save_image
from PIL import Image
import os

# Define Generator and Discriminator Networks
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        # Define architecture (UNet style generator)
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        # Define architecture (PatchGAN discriminator)
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.model(x)
        return x

# Custom Dataset class for pix2pix
class Pix2PixDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_files = sorted(os.listdir(os.path.join(root_dir, 'input')))

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        # Load paired images
        input_name = self.image_files[idx]
        target_name = input_name.replace('input', 'target')

        input_img = Image.open(os.path.join(self.root_dir, 'input', input_name)).convert('RGB')
        target_img = Image.open(os.path.join(self.root_dir, 'target', target_name)).convert('RGB')

        if self.transform:
            input_img = self.transform(input_img)
            target_img = self.transform(target_img)

        return input_img, target_img

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize Generator and Discriminator
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Define Loss function and Optimizers
criterion_GAN = nn.BCELoss()
criterion_pixelwise = nn.L1Loss()

optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# Dataset and DataLoader
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

# Example dataset setup (replace with your actual dataset path and structure)
# Assume a simple example dataset structure:

── input
│   ├── img1.jpg
│   ├── img2.jpg
│   └── ...
└── target
    ├── img1.jpg
    ├── img2.jpg
    └── ...
train_dataset = Pix2PixDataset(root_dir='Pix2PixDataset', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)

# Training Loop
num_epochs = 50
lambda_pixel = 100  # Weight for L1 loss

for epoch in range(num_epochs):
    for batch_idx, (real_images, target_images) in enumerate(train_loader):
        real_images = real_images.to(device)
        target_images = target_images.to(device)

        # Adversarial ground truths
        valid = torch.ones(real_images.size(0), 1, 30, 30).to(device)
        fake = torch.zeros(real_images.size(0), 1, 30, 30).to(device)

        ####################
        # Train Generator   #
        ####################

        optimizer_G.zero_grad()

        # Generate a batch of images
        gen_imgs = generator(real_images)

        # Adversarial and pixelwise loss
        loss_GAN = criterion_GAN(discriminator(gen_imgs), valid)
        loss_pixel = criterion_pixelwise(gen_imgs, target_images)
        loss_G = loss_GAN + lambda_pixel * loss_pixel

        loss_G.backward()
        optimizer_G.step()

        #######################
        # Train Discriminator #
        #######################

        optimizer_D.zero_grad()

        # Measure discriminator's ability to classify real from generated samples
        loss_real = criterion_GAN(discriminator(target_images), valid)
        loss_fake = criterion_GAN(discriminator(gen_imgs.detach()), fake)
        loss_D = 0.5 * (loss_real + loss_fake)

        loss_D.backward()
        optimizer_D.step()

        #######################
        # Print and save images #
        #######################
        if batch_idx % 100 == 0:
            print(
                f"[Epoch {epoch}/{num_epochs}] [Batch {batch_idx}/{len(train_loader)}] "
                f"[D loss: {loss_D.item():.4f}] [G loss: {loss_G.item():.4f}]"
            )

            # Save generated images
            os.makedirs("images", exist_ok=True)
            save_image(gen_imgs.data[:4], f"images/{epoch}_{batch_idx}.png", nrow=2, normalize=True)

# Example of generating images after training (using the trained generator)
with torch.no_grad():
    generator.eval()
    for batch_idx, (input_imgs, _) in enumerate(train_loader):
        input_imgs = input_imgs.to(device)
        gen_imgs = generator(input_imgs)
        save_image(gen_imgs, f"generated_image_{batch_idx}.png")
